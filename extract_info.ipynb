{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b80ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting web scraping...\n",
      "=== DEBUGGING TABLE STRUCTURE ===\n",
      "\n",
      "Found 5 tables on the page\n",
      "\n",
      "--- TABLE 1 ---\n",
      "Classes: ['table', 'datatable-table']\n",
      "ID: None\n",
      "Number of rows: 4\n",
      "  Row 1: 4 columns\n",
      "    Col 1: ''\n",
      "    Col 2: ''\n",
      "    Col 3: ''\n",
      "  Row 2: 4 columns\n",
      "    Col 1: ''\n",
      "    Col 2: ''\n",
      "    Col 3: ''\n",
      "  Row 3: 4 columns\n",
      "    Col 1: ''\n",
      "    Col 2: ''\n",
      "    Col 3: ''\n",
      "  Row 4: 4 columns\n",
      "    Col 1: ''\n",
      "    Col 2: ''\n",
      "    Col 3: ''\n",
      "\n",
      "--- TABLE 2 ---\n",
      "Classes: ['all-models-table', 'hidden']\n",
      "ID: models-all-models-35998bb201-table\n",
      "Number of rows: 4\n",
      "  Row 1: 5 columns\n",
      "    Col 1: 'Code'\n",
      "    Col 2: 'Actions'\n",
      "    Col 3: 'Price'\n",
      "  Row 2: 5 columns\n",
      "    Col 1: '-2245-X-I-'\n",
      "    Col 2: 'Not sellable online'\n",
      "    Col 3: ''\n",
      "  Row 3: 5 columns\n",
      "    Col 1: '-2245-X-L-'\n",
      "    Col 2: 'Not sellable online'\n",
      "    Col 3: ''\n",
      "  Row 4: 5 columns\n",
      "    Col 1: '-2245-X-LC-'\n",
      "    Col 2: 'Not sellable online'\n",
      "    Col 3: ''\n",
      "\n",
      "--- TABLE 3 ---\n",
      "Classes: ['catego-filelist']\n",
      "ID: None\n",
      "Number of rows: 3\n",
      "  Row 1: 3 columns\n",
      "    Col 1: 'B&K 2245 Sound Level Meter with Exhaust Noise Part'\n",
      "    Col 2: 'Data Sheets'\n",
      "    Col 3: 'English'\n",
      "  Row 2: 3 columns\n",
      "    Col 1: 'B&K 2245 Sound Level Meter'\n",
      "    Col 2: 'Data Sheets'\n",
      "    Col 3: 'English'\n",
      "  Row 3: 3 columns\n",
      "    Col 1: 'Instruction Manual -  B&K 2245 Sound Level Meter'\n",
      "    Col 2: 'Manual'\n",
      "    Col 3: 'English'\n",
      "\n",
      "--- TABLE 4 ---\n",
      "Classes: ['catego-filelist']\n",
      "ID: None\n",
      "Number of rows: 1\n",
      "  Row 1: 3 columns\n",
      "    Col 1: '2245 exhaust noise brochure'\n",
      "    Col 2: 'Brochure'\n",
      "    Col 3: 'English'\n",
      "\n",
      "--- TABLE 5 ---\n",
      "Classes: None\n",
      "ID: None\n",
      "Caption: Exhaust Noise Partner\n",
      "Number of rows: 19\n",
      "  Row 1: 2 columns\n",
      "    Col 1: 'Number of inputs'\n",
      "    Col 2: 'Single channel'\n",
      "  Row 2: 2 columns\n",
      "    Col 1: 'Standard'\n",
      "    Col 2: 'IEC 61672, ANSI S1.4, Other national standards'\n",
      "  Row 3: 2 columns\n",
      "    Col 1: 'Sound field'\n",
      "    Col 2: 'Free field, Diffuse field'\n",
      "  Row 4: 2 columns\n",
      "    Col 1: 'Polarization'\n",
      "    Col 2: 'None'\n",
      "  Row 5: 2 columns\n",
      "    Col 1: 'Sensitivity'\n",
      "    Col 2: '50 mV/Pa'\n",
      "  ... and 14 more rows\n",
      "\n",
      "=== LOOKING FOR SPECIFICATION PATTERNS ===\n",
      "Found 1 potential specification containers\n",
      "Container 1: ['specifications']\n",
      "\n",
      "=== TRYING ENHANCED EXTRACTION ===\n",
      "\n",
      "Found 27 potential specifications:\n",
      "Table: Code -> Actions\n",
      "Table: -2245-X-I- -> Not sellable online\n",
      "Table: -2245-X-L- -> Not sellable online\n",
      "Table: -2245-X-LC- -> Not sellable online\n",
      "Table: B&K 2245 Sound Level Meter with Exhaust Noise Partner -> Data Sheets\n",
      "Table: B&K 2245 Sound Level Meter -> Data Sheets\n",
      "Table: Instruction Manual -  B&K 2245 Sound Level Meter -> Manual\n",
      "Table: 2245 exhaust noise brochure -> Brochure\n",
      "Table: Number of inputs -> Single channel\n",
      "Table: Standard -> IEC 61672, ANSI S1.4, Other national standards\n",
      "\n",
      "Saved all 27 specifications to debug_specifications.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def scrape_with_requests_first(url):\n",
    "    \"\"\"Try scraping with requests first (faster and more stable)\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Requests failed: {e}. Trying Selenium...\")\n",
    "        return None\n",
    "\n",
    "def scrape_with_selenium(url):\n",
    "    \"\"\"Fallback to Selenium with proper configuration\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--window-size=1920,1080')\n",
    "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "    \n",
    "    driver = None\n",
    "    try:\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        driver.set_page_load_timeout(30)\n",
    "        \n",
    "        print(\"Loading page with Selenium...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the table to load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'table')))\n",
    "        \n",
    "        time.sleep(3)\n",
    "        return driver.page_source\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Selenium error: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "def debug_table_structure(html_content):\n",
    "    \"\"\"Debug the table structure to understand the layout\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    print(\"=== DEBUGGING TABLE STRUCTURE ===\\n\")\n",
    "    \n",
    "    # Find all tables\n",
    "    tables = soup.find_all('table')\n",
    "    print(f\"Found {len(tables)} tables on the page\")\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        print(f\"\\n--- TABLE {i+1} ---\")\n",
    "        print(f\"Classes: {table.get('class', 'None')}\")\n",
    "        print(f\"ID: {table.get('id', 'None')}\")\n",
    "        \n",
    "        # Check for caption\n",
    "        caption = table.find('caption')\n",
    "        if caption:\n",
    "            print(f\"Caption: {caption.get_text(strip=True)}\")\n",
    "        \n",
    "        # Get all rows\n",
    "        rows = table.find_all('tr')\n",
    "        print(f\"Number of rows: {len(rows)}\")\n",
    "        \n",
    "        # Show first few rows structure\n",
    "        for j, row in enumerate(rows[:5]):  # Show first 5 rows\n",
    "            cols = row.find_all(['td', 'th'])\n",
    "            print(f\"  Row {j+1}: {len(cols)} columns\")\n",
    "            for k, col in enumerate(cols[:3]):  # Show first 3 columns\n",
    "                text = col.get_text(strip=True)[:50]  # Truncate long text\n",
    "                print(f\"    Col {k+1}: '{text}'\")\n",
    "        \n",
    "        if len(rows) > 5:\n",
    "            print(f\"  ... and {len(rows) - 5} more rows\")\n",
    "    \n",
    "    # Look for common specification patterns\n",
    "    print(\"\\n=== LOOKING FOR SPECIFICATION PATTERNS ===\")\n",
    "    \n",
    "    # Look for divs or sections that might contain specs\n",
    "    spec_containers = soup.find_all(['div', 'section'], class_=lambda x: x and any(\n",
    "        word in str(x).lower() for word in ['spec', 'detail', 'feature', 'characteristic']\n",
    "    ))\n",
    "    \n",
    "    if spec_containers:\n",
    "        print(f\"Found {len(spec_containers)} potential specification containers\")\n",
    "        for i, container in enumerate(spec_containers[:3]):\n",
    "            print(f\"Container {i+1}: {container.get('class')}\")\n",
    "    \n",
    "    # Look for definition lists (dl, dt, dd)\n",
    "    dl_elements = soup.find_all('dl')\n",
    "    if dl_elements:\n",
    "        print(f\"Found {len(dl_elements)} definition lists\")\n",
    "        for i, dl in enumerate(dl_elements[:2]):\n",
    "            dt_elements = dl.find_all('dt')\n",
    "            dd_elements = dl.find_all('dd')\n",
    "            print(f\"  DL {i+1}: {len(dt_elements)} terms, {len(dd_elements)} definitions\")\n",
    "\n",
    "def extract_specifications_enhanced(html_content):\n",
    "    \"\"\"Enhanced extraction with multiple strategies\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Strategy 1: Look for tables\n",
    "    tables = soup.find_all('table')\n",
    "    for table in tables:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all(['td', 'th'])\n",
    "            if len(cols) >= 2:\n",
    "                label = cols[0].get_text(separator=' ', strip=True)\n",
    "                value = cols[1].get_text(separator=' ', strip=True)\n",
    "                if label and value and len(label) > 2 and len(value) > 0:\n",
    "                    data.append(('Table', label, value))\n",
    "    \n",
    "    # Strategy 2: Look for definition lists\n",
    "    dl_elements = soup.find_all('dl')\n",
    "    for dl in dl_elements:\n",
    "        dt_elements = dl.find_all('dt')\n",
    "        dd_elements = dl.find_all('dd')\n",
    "        for dt, dd in zip(dt_elements, dd_elements):\n",
    "            label = dt.get_text(strip=True)\n",
    "            value = dd.get_text(strip=True)\n",
    "            if label and value:\n",
    "                data.append(('Definition List', label, value))\n",
    "    \n",
    "    # Strategy 3: Look for key-value pairs in divs\n",
    "    spec_patterns = [\n",
    "        ('div', 'spec'),\n",
    "        ('div', 'feature'),\n",
    "        ('div', 'detail'),\n",
    "        ('span', 'spec'),\n",
    "        ('p', 'spec')\n",
    "    ]\n",
    "    \n",
    "    for tag, class_keyword in spec_patterns:\n",
    "        elements = soup.find_all(tag, class_=lambda x: x and class_keyword in str(x).lower())\n",
    "        for elem in elements:\n",
    "            text = elem.get_text(strip=True)\n",
    "            if ':' in text:\n",
    "                parts = text.split(':', 1)\n",
    "                if len(parts) == 2:\n",
    "                    label = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    if label and value:\n",
    "                        data.append((f'{tag.upper()} ({class_keyword})', label, value))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.hbkworld.com/en/products/instruments/handheld/sound-level-meters/type-2245/2245-exhaust-noise\"\n",
    "    \n",
    "    print(\"Starting web scraping...\")\n",
    "    \n",
    "    # Try requests first\n",
    "    html_content = scrape_with_requests_first(url)\n",
    "    \n",
    "    # Fallback to Selenium if requests fails\n",
    "    if not html_content:\n",
    "        html_content = scrape_with_selenium(url)\n",
    "    \n",
    "    if not html_content:\n",
    "        print(\"Failed to retrieve page content\")\n",
    "        return\n",
    "    \n",
    "    # Debug the page structure\n",
    "    debug_table_structure(html_content)\n",
    "    \n",
    "    # Try enhanced extraction\n",
    "    print(\"\\n=== TRYING ENHANCED EXTRACTION ===\")\n",
    "    data = extract_specifications_enhanced(html_content)\n",
    "    \n",
    "    if data:\n",
    "        print(f\"\\nFound {len(data)} potential specifications:\")\n",
    "        for source, label, value in data[:10]:  # Show first 10\n",
    "            print(f\"{source}: {label} -> {value}\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        filename = \"debug_specifications.csv\"\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Source', 'Specification', 'Value'])\n",
    "            writer.writerows(data)\n",
    "        \n",
    "        print(f\"\\nSaved all {len(data)} specifications to {filename}\")\n",
    "    else:\n",
    "        print(\"No specifications found with any method\")\n",
    "        \n",
    "        # Save the HTML for manual inspection\n",
    "        with open('debug_page.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        print(\"Saved page HTML as 'debug_page.html' for manual inspection\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
