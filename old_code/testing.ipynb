{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24481ef7",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082641f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import NonLLMContextPrecisionWithReference\n",
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
    "from ragas.metrics import NoiseSensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addb58c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_7200\\1909013780.py:4: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3.1\")\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_7200\\1909013780.py:5: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  evaluator_llm = LangchainLLMWrapper(llm)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "evaluator_llm = LangchainLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a54ae",
   "metadata": {},
   "source": [
    "Read Ground truth and get var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199e1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which solution is suitable for measuring room acoustics and speech intelligibility in compliance with ISO standards?\n",
      "Reference answer: DIRAC Room Acoustics Software with HBK 2255 and HBK 2755.\n",
      "Number of context texts: 3\n",
      "First context snippet: DIRAC Room Acoustics Software is used for measuring a wide range of room acoustical parameters. It supports wireless measurements using HBK 2255 Sound Level Meter and HBK 2755 Smart Power Amplifier. I ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = r\"gt.json\"\n",
    "\n",
    "# Load the JSON safely\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Build a list of tuples: (question, reference_answer, [list of context texts])\n",
    "query_texts_pairs = [\n",
    "    (\n",
    "        item[\"question\"].strip(),\n",
    "        item[\"reference\"].strip(),\n",
    "        [seg.strip() for seg in item.get(\"context\", [])]\n",
    "    )\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# Example: show the first query and its data\n",
    "first_query, first_reference, first_contexts = query_texts_pairs[0]\n",
    "print(\"Query:\", first_query)\n",
    "print(\"Reference answer:\", first_reference)\n",
    "print(\"Number of context texts:\", len(first_contexts))\n",
    "print(\"First context snippet:\", first_contexts[0][:200].replace(\"\\n\", \" \"), \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ad22d",
   "metadata": {},
   "source": [
    "read dense json and get question and texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea936817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which solution is suitable for measuring room acoustics and speech intelligibility in compliance with ISO standards?\n",
      "Number of retrieved texts: 2\n",
      "First retrieved text snippet: Speech intelligibility measurements can be carried out in compliance with the IEC 60268-16 standard, for male and female voices, through an artificial mouth-directional loudspeaker sound source or thr ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to your RAG output JSON\n",
    "path = r\"retrieval_results_dense.json\"\n",
    "\n",
    "# Load the JSON\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    rag_data_dense = json.load(f)\n",
    "\n",
    "# Build a list of tuples: (query, [list of retrieved texts])\n",
    "query_retrieved_pairs_dense = [\n",
    "    (\n",
    "        query,\n",
    "        [item[\"text\"].strip() for item in texts]\n",
    "    )\n",
    "    for query, texts in rag_data_dense.items()\n",
    "]\n",
    "\n",
    "# Example: show the first query and its retrieved texts\n",
    "first_query, first_texts = query_retrieved_pairs_dense[0]\n",
    "print(\"Query:\", first_query)\n",
    "print(\"Number of retrieved texts:\", len(first_texts))\n",
    "print(\"First retrieved text snippet:\", first_texts[0][:200].replace(\"\\n\", \" \"), \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c853d9",
   "metadata": {},
   "source": [
    "Same with the sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e33200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Which solution is suitable for measuring room acoustics and speech intelligibility in compliance with ISO standards?\n",
      "Number of retrieved texts: 2\n",
      "First retrieved text snippet: 5  Regression line through the speech sound levels, indicating the spatial decay  of sound A similar graph can be generated for the speech transmission  index (STI) with a regression line to calculate ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to your BM25 output JSON\n",
    "path = r\"retrieval_results_sparse.json\"\n",
    "\n",
    "# Load the JSON\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    bm25_data = json.load(f)\n",
    "\n",
    "# Build a list of tuples: (query, [list of retrieved texts])\n",
    "query_retrieved_pairs_sparse = [\n",
    "    (\n",
    "        item[\"query\"],\n",
    "        [res[\"window\"].strip() for res in item[\"results\"]]\n",
    "    )\n",
    "    for item in bm25_data\n",
    "]\n",
    "\n",
    "# Example: show the first query and its retrieved texts\n",
    "first_query, first_texts = query_retrieved_pairs_sparse[0]\n",
    "print(\"Query:\", first_query)\n",
    "print(\"Number of retrieved texts:\", len(first_texts))\n",
    "print(\"First retrieved text snippet:\", first_texts[0][:200].replace(\"\\n\", \" \"), \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9903e9a",
   "metadata": {},
   "source": [
    "LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa255af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense pairs found: 24\n",
      "Sparse pairs found: 24\n"
     ]
    }
   ],
   "source": [
    "# Load chat logs and separate by mode\n",
    "path = r\"chat_logs.json\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dense_pairs = []\n",
    "sparse_pairs = []\n",
    "\n",
    "for item in data:\n",
    "    query = item.get(\"query\", \"\").strip()\n",
    "    mode = item.get(\"mode\", \"\").strip().lower()\n",
    "    response = item.get(\"response\", \"\").strip()\n",
    "    \n",
    "    if mode == \"dense rag\":\n",
    "        dense_pairs.append((query, response))\n",
    "    elif mode == \"sparse rag\":\n",
    "        sparse_pairs.append((query, response))\n",
    "\n",
    "print(\"Dense pairs found:\", len(dense_pairs))\n",
    "print(\"Sparse pairs found:\", len(sparse_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceade81b",
   "metadata": {},
   "source": [
    "### Context Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa156f67",
   "metadata": {},
   "source": [
    "#### DENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c4a94",
   "metadata": {},
   "source": [
    "Context Precision WITH reference - NON LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d8670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense - Query: Which solution is suitable for measuring room acoustics and speech intelligibility in compliance with ISO standards?\n",
      "Score: 0.99999999995\n",
      "\n",
      "Dense - Query: What product should be used for façade sound insulation testing on a construction site?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which sound source is recommended for calibrated speech intelligibility measurements using DIRAC?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What sound source should be used for ISO 3382-compliant room acoustics measurements?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which product supports compliance with ISO 9612 for workplace noise exposure?\n",
      "Score: 0.99999999995\n",
      "\n",
      "Dense - Query: Which product is suitable for investigating environmental noise complaints?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which product is designed for measuring exhaust noise in vehicles?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which product helps verify safe noise emissions from toys and machinery?\n",
      "Score: 0.99999999995\n",
      "\n",
      "Dense - Query: Which HBK 2255 variant is best suited for long-term environmental noise monitoring in infrastructure projects?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which HBK 2255 variant should be used for evaluating workplace noise exposure according to ISO 9612?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What HBK 2255 variant is recommended for sound insulation testing in buildings?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which software module allows isolating specific noise events like barking dogs or traffic during environmental surveys?\n",
      "Score: 0.99999999995\n",
      "\n",
      "Dense - Query: Which loudspeaker should be used for measuring airborne sound insulation in residential buildings?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What amplifier is recommended for driving the OmniPower sound source in concert hall reverberation tests?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which amplifier version should be selected if remote control via mobile device is required?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What sound source is suitable for ISO 3382 compliant reverberation time measurements in office buildings?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which B&K 2245 variant is best suited for sound power measurements in a product testing lab?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What software is required on the B&K 2245 to comply with ISO 3744 for sound power testing?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which B&K 2245 variant is suitable for environmental noise surveys and regulation compliance?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What variant should be used for roadside exhaust noise enforcement?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which sound level meter is best suited for a technician doing quick spot checks in urban environments?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What product variant of HBK 2255 should a small business owner choose for basic environmental noise monitoring?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: Which HBK 2255 variant includes both environmental noise monitoring and a calibrator for accurate measurements?\n",
      "Score: 0.0\n",
      "\n",
      "Dense - Query: What sound level meter is recommended for community noise monitoring with mobile app support?\n",
      "Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure prerequisite variables are available\n",
    "if 'query_texts_pairs' not in globals() or 'query_retrieved_pairs_dense' not in globals():\n",
    "    raise NameError(\n",
    "        \"query_texts_pairs and/or query_retrieved_pairs_dense are not defined. \"\n",
    "        \"Please run the cells that load ground truth (cell that creates query_texts_pairs) \"\n",
    "        \"and dense retrieval results (cell that creates query_retrieved_pairs_dense) before this cell.\"\n",
    "    )\n",
    "\n",
    "# Initialize metric\n",
    "context_precision = NonLLMContextPrecisionWithReference()\n",
    "\n",
    "# Store scores\n",
    "dense_scores = []\n",
    "sparse_scores = []\n",
    "\n",
    "# Loop over all queries for Dense retrieval\n",
    "# Note: query_texts_pairs elements are (query, ground_truth_answer, [reference_texts])\n",
    "for (query_gt, gt_answer, gt_texts), (query_dense, dense_texts) in zip(query_texts_pairs, query_retrieved_pairs_dense):\n",
    "    # Sanity check: queries should match\n",
    "    assert query_gt == query_dense, f\"Query mismatch: {query_gt} vs {query_dense}\"\n",
    "\n",
    "    # Build sample (NonLLM metric expects reference_contexts + retrieved_contexts)\n",
    "    sample = SingleTurnSample(\n",
    "        retrieved_contexts=dense_texts,\n",
    "        reference_contexts=gt_texts\n",
    "    )\n",
    "\n",
    "    # Compute score (async)\n",
    "    score = await context_precision.single_turn_ascore(sample)\n",
    "    dense_scores.append((query_gt, score))\n",
    "    print(f\"Dense - Query: {query_gt}\\nScore: {score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138121a",
   "metadata": {},
   "source": [
    "Context Precision WITH Reference - LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d7af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Dense RAG (With Reference) ===\n",
      "Dense - Query: Which solution is suitable for measuring room acoustics and ... Score: 0.0\n",
      "Dense - Query: What product should be used for façade sound insulation test... Score: 0.0\n",
      "Dense - Query: Which sound source is recommended for calibrated speech inte... Score: 0.9999999999\n",
      "Dense - Query: What sound source should be used for ISO 3382-compliant room... Score: 0.99999999995\n",
      "Dense - Query: Which product supports compliance with ISO 9612 for workplac... Score: 0.99999999995\n",
      "Dense - Query: Which product is suitable for investigating environmental no... Score: 0.99999999995\n",
      "Dense - Query: Which product is designed for measuring exhaust noise in veh... Score: 0.99999999995\n",
      "Dense - Query: Which product helps verify safe noise emissions from toys an... Score: 0.99999999995\n",
      "Dense - Query: Which HBK 2255 variant is best suited for long-term environm... Score: 0.9999999999\n",
      "Dense - Query: Which HBK 2255 variant should be used for evaluating workpla... Score: 0.0\n",
      "Dense - Query: What HBK 2255 variant is recommended for sound insulation te... Score: 0.0\n",
      "Dense - Query: Which software module allows isolating specific noise events... Score: 0.99999999995\n",
      "Dense - Query: Which loudspeaker should be used for measuring airborne soun... Score: 0.0\n",
      "Dense - Query: What amplifier is recommended for driving the OmniPower soun... Score: 0.0\n",
      "Dense - Query: Which amplifier version should be selected if remote control... Score: 0.0\n",
      "Dense - Query: What sound source is suitable for ISO 3382 compliant reverbe... Score: 0.0\n",
      "Dense - Query: Which B&K 2245 variant is best suited for sound power measur... Score: 0.99999999995\n",
      "Dense - Query: What software is required on the B&K 2245 to comply with ISO... Score: 0.99999999995\n",
      "Dense - Query: Which B&K 2245 variant is suitable for environmental noise s... Score: 0.99999999995\n",
      "Dense - Query: What variant should be used for roadside exhaust noise enfor... Score: 0.0\n",
      "Dense - Query: Which sound level meter is best suited for a technician doin... Score: 0.0\n",
      "Dense - Query: What product variant of HBK 2255 should a small business own... Score: 0.0\n",
      "Dense - Query: Which HBK 2255 variant includes both environmental noise mon... Score: 0.0\n",
      "Dense - Query: What sound level meter is recommended for community noise mo... Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "context_precision = LLMContextPrecisionWithReference(llm=evaluator_llm)\n",
    "\n",
    "# Evaluate Dense RAG\n",
    "print(\"\\n=== Evaluating Dense RAG (With Reference) ===\")\n",
    "dense_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_dense, dense_texts) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_dense\n",
    "):\n",
    "    assert query_gt == query_dense, f\"Query mismatch\"\n",
    "\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=query_gt,\n",
    "        reference=gt_answer,  # Ground truth answer\n",
    "        retrieved_contexts=dense_texts\n",
    "    )\n",
    "\n",
    "    score = await context_precision.single_turn_ascore(sample)\n",
    "    print(f\"Dense - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    dense_scores.append((query_gt, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4064c",
   "metadata": {},
   "source": [
    "Context Precision Without Reference - LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c89d0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Dense RAG ===\n",
      "Dense - Query: Which solution is suitable for measuring room acoustics and ... Score: 0.9999999999\n",
      "Dense - Query: What product should be used for façade sound insulation test... Score: 0.0\n",
      "Dense - Query: Which sound source is recommended for calibrated speech inte... Score: 0.99999999995\n",
      "Dense - Query: What sound source should be used for ISO 3382-compliant room... Score: 0.99999999995\n",
      "Dense - Query: Which product supports compliance with ISO 9612 for workplac... Score: 0.99999999995\n",
      "Dense - Query: Which product is suitable for investigating environmental no... Score: 0.99999999995\n",
      "Dense - Query: Which product is designed for measuring exhaust noise in veh... Score: 0.99999999995\n",
      "Dense - Query: Which product helps verify safe noise emissions from toys an... Score: 0.99999999995\n",
      "Dense - Query: Which HBK 2255 variant is best suited for long-term environm... Score: 0.0\n",
      "Dense - Query: Which HBK 2255 variant should be used for evaluating workpla... Score: 0.0\n",
      "Dense - Query: What HBK 2255 variant is recommended for sound insulation te... Score: 0.0\n",
      "Dense - Query: Which software module allows isolating specific noise events... Score: 0.99999999995\n",
      "Dense - Query: Which loudspeaker should be used for measuring airborne soun... Score: 0.0\n",
      "Dense - Query: What amplifier is recommended for driving the OmniPower soun... Score: 0.0\n",
      "Dense - Query: Which amplifier version should be selected if remote control... Score: 0.99999999995\n",
      "Dense - Query: What sound source is suitable for ISO 3382 compliant reverbe... Score: 0.0\n",
      "Dense - Query: Which B&K 2245 variant is best suited for sound power measur... Score: 0.99999999995\n",
      "Dense - Query: What software is required on the B&K 2245 to comply with ISO... Score: 0.0\n",
      "Dense - Query: Which B&K 2245 variant is suitable for environmental noise s... Score: 0.99999999995\n",
      "Dense - Query: What variant should be used for roadside exhaust noise enfor... Score: 0.99999999995\n",
      "Dense - Query: Which sound level meter is best suited for a technician doin... Score: 0.0\n",
      "Dense - Query: What product variant of HBK 2255 should a small business own... Score: 0.0\n",
      "Dense - Query: Which HBK 2255 variant includes both environmental noise mon... Score: 0.0\n",
      "Dense - Query: What sound level meter is recommended for community noise mo... Score: 0.99999999995\n"
     ]
    }
   ],
   "source": [
    "context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "\n",
    "# Evaluate Dense RAG\n",
    "print(\"\\n=== Evaluating Dense RAG ===\")\n",
    "dense_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_dense, dense_texts), (query_response, response) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_dense, \n",
    "    dense_pairs\n",
    "):\n",
    "    # Sanity check\n",
    "    assert query_gt == query_dense == query_response, f\"Query mismatch: {query_gt} vs {query_dense} vs {query_response}\"\n",
    "\n",
    "    # Build sample\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=query_gt,\n",
    "        response=response,  # LLM's actual response\n",
    "        retrieved_contexts=dense_texts\n",
    "    )\n",
    "\n",
    "    # Compute score\n",
    "    score = await context_precision.single_turn_ascore(sample)\n",
    "    print(f\"Dense - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    dense_scores.append((query_gt, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbaf77",
   "metadata": {},
   "source": [
    "#### Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d887fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse - Query: Which solution is suitable for measuring room acoustics and speech intelligibility in compliance with ISO standards?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What product should be used for façade sound insulation testing on a construction site?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which sound source is recommended for calibrated speech intelligibility measurements using DIRAC?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What sound source should be used for ISO 3382-compliant room acoustics measurements?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which product supports compliance with ISO 9612 for workplace noise exposure?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which product is suitable for investigating environmental noise complaints?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which product is designed for measuring exhaust noise in vehicles?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which product helps verify safe noise emissions from toys and machinery?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which HBK 2255 variant is best suited for long-term environmental noise monitoring in infrastructure projects?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which HBK 2255 variant should be used for evaluating workplace noise exposure according to ISO 9612?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What HBK 2255 variant is recommended for sound insulation testing in buildings?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which software module allows isolating specific noise events like barking dogs or traffic during environmental surveys?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which loudspeaker should be used for measuring airborne sound insulation in residential buildings?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What amplifier is recommended for driving the OmniPower sound source in concert hall reverberation tests?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which amplifier version should be selected if remote control via mobile device is required?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What sound source is suitable for ISO 3382 compliant reverberation time measurements in office buildings?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which B&K 2245 variant is best suited for sound power measurements in a product testing lab?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What software is required on the B&K 2245 to comply with ISO 3744 for sound power testing?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which B&K 2245 variant is suitable for environmental noise surveys and regulation compliance?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What variant should be used for roadside exhaust noise enforcement?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which sound level meter is best suited for a technician doing quick spot checks in urban environments?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What product variant of HBK 2255 should a small business owner choose for basic environmental noise monitoring?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: Which HBK 2255 variant includes both environmental noise monitoring and a calibrator for accurate measurements?\n",
      "Score: 0.0\n",
      "\n",
      "Sparse - Query: What sound level meter is recommended for community noise monitoring with mobile app support?\n",
      "Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure prerequisite variables are available\n",
    "if 'query_texts_pairs' not in globals() or 'query_retrieved_pairs_dense' not in globals():\n",
    "    raise NameError(\n",
    "        \"query_texts_pairs and/or query_retrieved_pairs_dense are not defined. \"\n",
    "        \"Please run the cells that load ground truth (cell that creates query_texts_pairs) \"\n",
    "        \"and dense retrieval results (cell that creates query_retrieved_pairs_dense) before this cell.\"\n",
    "    )\n",
    "\n",
    "# Initialize metric\n",
    "context_precision = NonLLMContextPrecisionWithReference()\n",
    "\n",
    "\n",
    "sparse_scores = []\n",
    "\n",
    "# Loop over all queries for Sparse retrieval\n",
    "# Note: query_texts_pairs elements are (query, ground_truth_answer, [reference_texts])\n",
    "for (query_gt, gt_answer, gt_texts), (query_sparse, sparse_texts) in zip(query_texts_pairs, query_retrieved_pairs_sparse):\n",
    "    # Sanity check: queries should match\n",
    "    assert query_gt == query_sparse, f\"Query mismatch: {query_gt} vs {query_sparse}\"\n",
    "\n",
    "    # Build sample (NonLLM metric expects reference_contexts + retrieved_contexts)\n",
    "    sample = SingleTurnSample(\n",
    "        retrieved_contexts=sparse_texts,\n",
    "        reference_contexts=gt_texts\n",
    "    )\n",
    "\n",
    "    # Compute score (async)\n",
    "    score = await context_precision.single_turn_ascore(sample)\n",
    "    sparse_scores.append((query_gt, score))\n",
    "    print(f\"Sparse - Query: {query_gt}\\nScore: {score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce148fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Sparse RAG (With Reference) ===\n",
      "Sparse - Query: Which solution is suitable for measuring room acoustics and ... Score: 0.99999999995\n",
      "Sparse - Query: What product should be used for façade sound insulation test... Score: 0.0\n",
      "Sparse - Query: Which sound source is recommended for calibrated speech inte... Score: 0.99999999995\n",
      "Sparse - Query: What sound source should be used for ISO 3382-compliant room... Score: 0.99999999995\n",
      "Sparse - Query: Which product supports compliance with ISO 9612 for workplac... Score: 0.99999999995\n",
      "Sparse - Query: Which product is suitable for investigating environmental no... Score: 0.99999999995\n",
      "Sparse - Query: Which product is designed for measuring exhaust noise in veh... Score: 0.99999999995\n",
      "Sparse - Query: Which product helps verify safe noise emissions from toys an... Score: 0.99999999995\n",
      "Sparse - Query: Which HBK 2255 variant is best suited for long-term environm... Score: 0.99999999995\n",
      "Sparse - Query: Which HBK 2255 variant should be used for evaluating workpla... Score: 0.0\n",
      "Sparse - Query: What HBK 2255 variant is recommended for sound insulation te... Score: 0.9999999999\n",
      "Sparse - Query: Which software module allows isolating specific noise events... Score: 0.99999999995\n",
      "Sparse - Query: Which loudspeaker should be used for measuring airborne soun... Score: 0.0\n",
      "Sparse - Query: What amplifier is recommended for driving the OmniPower soun... Score: 0.9999999999\n",
      "Sparse - Query: Which amplifier version should be selected if remote control... Score: 0.9999999999\n",
      "Sparse - Query: What sound source is suitable for ISO 3382 compliant reverbe... Score: 0.99999999995\n",
      "Sparse - Query: Which B&K 2245 variant is best suited for sound power measur... Score: 0.99999999995\n",
      "Sparse - Query: What software is required on the B&K 2245 to comply with ISO... Score: 0.99999999995\n",
      "Sparse - Query: Which B&K 2245 variant is suitable for environmental noise s... Score: 0.99999999995\n",
      "Sparse - Query: What variant should be used for roadside exhaust noise enfor... Score: 0.99999999995\n",
      "Sparse - Query: Which sound level meter is best suited for a technician doin... Score: 0.0\n",
      "Sparse - Query: What product variant of HBK 2255 should a small business own... Score: 0.99999999995\n",
      "Sparse - Query: Which HBK 2255 variant includes both environmental noise mon... Score: 0.49999999995\n",
      "Sparse - Query: What sound level meter is recommended for community noise mo... Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "context_precision = LLMContextPrecisionWithReference(llm=evaluator_llm)\n",
    "\n",
    "# Evaluate Sparse RAG\n",
    "print(\"\\n=== Evaluating Sparse RAG (With Reference) ===\")\n",
    "sparse_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_sparse, sparse_texts) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_sparse\n",
    "):\n",
    "    assert query_gt == query_sparse, f\"Query mismatch: {query_gt} vs {query_sparse}\"\n",
    "\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=query_gt,\n",
    "        reference=gt_answer,  # Ground truth answer\n",
    "        retrieved_contexts=sparse_texts\n",
    "    )\n",
    "\n",
    "    score = await context_precision.single_turn_ascore(sample)\n",
    "    print(f\"Sparse - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    sparse_scores.append((query_gt, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a218e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Sparse RAG ===\n",
      "Sparse - Query: Which solution is suitable for measuring room acoustics and ... Score: 0.99999999995\n",
      "Sparse - Query: What product should be used for façade sound insulation test... Score: 0.0\n",
      "Sparse - Query: Which sound source is recommended for calibrated speech inte... Score: 0.99999999995\n",
      "Sparse - Query: What sound source should be used for ISO 3382-compliant room... Score: 0.99999999995\n",
      "Sparse - Query: Which product supports compliance with ISO 9612 for workplac... Score: 0.99999999995\n",
      "Sparse - Query: Which product is suitable for investigating environmental no... Score: 0.99999999995\n",
      "Sparse - Query: Which product is designed for measuring exhaust noise in veh... Score: 0.99999999995\n",
      "Sparse - Query: Which product helps verify safe noise emissions from toys an... Score: 0.99999999995\n",
      "Sparse - Query: Which HBK 2255 variant is best suited for long-term environm... Score: 0.99999999995\n",
      "Sparse - Query: Which HBK 2255 variant should be used for evaluating workpla... Score: 0.0\n",
      "Sparse - Query: What HBK 2255 variant is recommended for sound insulation te... Score: 0.99999999995\n",
      "Sparse - Query: Which software module allows isolating specific noise events... Score: 0.99999999995\n",
      "Sparse - Query: Which loudspeaker should be used for measuring airborne soun... Score: 0.0\n",
      "Sparse - Query: What amplifier is recommended for driving the OmniPower soun... Score: 0.49999999995\n",
      "Sparse - Query: Which amplifier version should be selected if remote control... Score: 0.49999999995\n",
      "Sparse - Query: What sound source is suitable for ISO 3382 compliant reverbe... Score: 0.99999999995\n",
      "Sparse - Query: Which B&K 2245 variant is best suited for sound power measur... Score: 0.99999999995\n",
      "Sparse - Query: What software is required on the B&K 2245 to comply with ISO... Score: 0.0\n",
      "Sparse - Query: Which B&K 2245 variant is suitable for environmental noise s... Score: 0.99999999995\n",
      "Sparse - Query: What variant should be used for roadside exhaust noise enfor... Score: 0.99999999995\n",
      "Sparse - Query: Which sound level meter is best suited for a technician doin... Score: 0.0\n",
      "Sparse - Query: What product variant of HBK 2255 should a small business own... Score: 0.49999999995\n",
      "Sparse - Query: Which HBK 2255 variant includes both environmental noise mon... Score: 0.0\n",
      "Sparse - Query: What sound level meter is recommended for community noise mo... Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "\n",
    "# Evaluate Sparse RAG\n",
    "print(\"\\n=== Evaluating Sparse RAG ===\")\n",
    "sparse_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_sparse, sparse_texts), (query_response, response) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_sparse, \n",
    "    sparse_pairs\n",
    "):\n",
    "    # Sanity check\n",
    "    assert query_gt == query_sparse == query_response, f\"Query mismatch: {query_gt} vs {query_sparse} vs {query_response}\"\n",
    "\n",
    "    # Build sample\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=query_gt,\n",
    "        response=response,  # LLM's actual response\n",
    "        retrieved_contexts=sparse_texts\n",
    "    )\n",
    "\n",
    "    # Compute score\n",
    "    score = await context_precision.single_turn_ascore(sample)\n",
    "    print(f\"Sparse - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    sparse_scores.append((query_gt, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706ab46",
   "metadata": {},
   "source": [
    "### Noise Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f1682",
   "metadata": {},
   "source": [
    "#### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57569b60",
   "metadata": {},
   "source": [
    "#### Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557d0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Sparse RAG (NoiseSensitivity) ===\n",
      "Sparse - Query: Which solution is suitable for measuring room acoustics and ... Score: 0.6\n",
      "Sparse - Query: What product should be used for façade sound insulation test... Score: 0.0\n",
      "Sparse - Query: Which sound source is recommended for calibrated speech inte... Score: 1.0\n",
      "Sparse - Query: What sound source should be used for ISO 3382-compliant room... Score: 0.3333333333333333\n",
      "Sparse - Query: Which product supports compliance with ISO 9612 for workplac... Score: 0.25\n",
      "Sparse - Query: Which product is suitable for investigating environmental no... Score: 0.5\n",
      "Sparse - Query: Which product is designed for measuring exhaust noise in veh... Score: 0.0\n",
      "Sparse - Query: Which product helps verify safe noise emissions from toys an... Score: 0.6666666666666666\n",
      "Sparse - Query: Which HBK 2255 variant is best suited for long-term environm... Score: 0.2\n",
      "Sparse - Query: Which HBK 2255 variant should be used for evaluating workpla... Score: 0.0\n",
      "Sparse - Query: What HBK 2255 variant is recommended for sound insulation te... Score: 0.0\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     15\u001b[39m sample = SingleTurnSample(\n\u001b[32m     16\u001b[39m user_input=query_gt,\n\u001b[32m     17\u001b[39m response=response,\n\u001b[32m     18\u001b[39m reference=gt_answer,\n\u001b[32m     19\u001b[39m retrieved_contexts=sparse_texts\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m scorer = NoiseSensitivity(llm=evaluator_llm)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m score = \u001b[38;5;28;01mawait\u001b[39;00m scorer.single_turn_ascore(sample)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSparse - Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_gt[:\u001b[32m60\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m... Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m sparse_scores.append((query_gt, score))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\metrics\\base.py:554\u001b[39m, in \u001b[36mSingleTurnMetric.single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    547\u001b[39m rm, group_cm = new_group(\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    549\u001b[39m     inputs=sample.to_dict(),\n\u001b[32m    550\u001b[39m     callbacks=callbacks,\n\u001b[32m    551\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.METRIC},\n\u001b[32m    552\u001b[39m )\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     score = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    555\u001b[39m         \u001b[38;5;28mself\u001b[39m._single_turn_ascore(sample=sample, callbacks=group_cm),\n\u001b[32m    556\u001b[39m         timeout=timeout,\n\u001b[32m    557\u001b[39m     )\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\metrics\\_noise_sensitivity.py:117\u001b[39m, in \u001b[36mNoiseSensitivity._single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_single_turn_ascore\u001b[39m(\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m, sample: SingleTurnSample, callbacks: Callbacks\n\u001b[32m    115\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    116\u001b[39m     row = sample.to_dict()\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ascore(row, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\metrics\\_noise_sensitivity.py:155\u001b[39m, in \u001b[36mNoiseSensitivity._ascore\u001b[39m\u001b[34m(self, row, callbacks)\u001b[39m\n\u001b[32m    152\u001b[39m ans_verdictslist = []\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ctx \u001b[38;5;129;01min\u001b[39;00m row[\u001b[33m\"\u001b[39m\u001b[33mretrieved_contexts\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     verdicts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._evaluate_statement_faithfulness(\n\u001b[32m    156\u001b[39m         gt_statements, ctx, callbacks\n\u001b[32m    157\u001b[39m     )\n\u001b[32m    158\u001b[39m     gt_verdictslist.append(np.array(verdicts))\n\u001b[32m    160\u001b[39m     verdicts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._evaluate_statement_faithfulness(\n\u001b[32m    161\u001b[39m         ans_statements, ctx, callbacks\n\u001b[32m    162\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\metrics\\_noise_sensitivity.py:63\u001b[39m, in \u001b[36mNoiseSensitivity._evaluate_statement_faithfulness\u001b[39m\u001b[34m(self, statements, context, callbacks)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate_statement_faithfulness\u001b[39m(\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m, statements: t.List[\u001b[38;5;28mstr\u001b[39m], context: \u001b[38;5;28mstr\u001b[39m, callbacks: Callbacks\n\u001b[32m     60\u001b[39m ) -> t.List[\u001b[38;5;28mint\u001b[39m]:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mLLM is not set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     verdicts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nli_statements_prompt.generate(\n\u001b[32m     64\u001b[39m         data=NLIStatementInput(context=context, statements=statements),\n\u001b[32m     65\u001b[39m         llm=\u001b[38;5;28mself\u001b[39m.llm,\n\u001b[32m     66\u001b[39m         callbacks=callbacks,\n\u001b[32m     67\u001b[39m     )\n\u001b[32m     69\u001b[39m     verdict_list = [\n\u001b[32m     70\u001b[39m         \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m statement.verdict \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m statement \u001b[38;5;129;01min\u001b[39;00m verdicts.statements\n\u001b[32m     71\u001b[39m     ]\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m verdict_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\prompt\\pydantic_prompt.py:168\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    165\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    169\u001b[39m     llm=llm,\n\u001b[32m    170\u001b[39m     data=data,\n\u001b[32m    171\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    172\u001b[39m     temperature=temperature,\n\u001b[32m    173\u001b[39m     stop=stop,\n\u001b[32m    174\u001b[39m     callbacks=callbacks,\n\u001b[32m    175\u001b[39m     retries_left=retries_left,\n\u001b[32m    176\u001b[39m )\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\prompt\\pydantic_prompt.py:246\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# This is a Ragas LLM - use generate()\u001b[39;00m\n\u001b[32m    245\u001b[39m     ragas_llm = t.cast(BaseRagasLLM, llm)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m ragas_llm.generate(\n\u001b[32m    247\u001b[39m         prompt_value,\n\u001b[32m    248\u001b[39m         n=n,\n\u001b[32m    249\u001b[39m         temperature=temperature,\n\u001b[32m    250\u001b[39m         stop=stop,\n\u001b[32m    251\u001b[39m         callbacks=prompt_cb,\n\u001b[32m    252\u001b[39m     )\n\u001b[32m    254\u001b[39m output_models = []\n\u001b[32m    255\u001b[39m parser = RagasOutputParser(pydantic_object=\u001b[38;5;28mself\u001b[39m.output_model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\llms\\base.py:116\u001b[39m, in \u001b[36mBaseRagasLLM.generate\u001b[39m\u001b[34m(self, prompt, n, temperature, stop, callbacks)\u001b[39m\n\u001b[32m    111\u001b[39m     temperature = \u001b[38;5;28mself\u001b[39m.get_temperature(n)\n\u001b[32m    113\u001b[39m agenerate_text_with_retry = add_async_retry(\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m.agenerate_text, \u001b[38;5;28mself\u001b[39m.run_config\n\u001b[32m    115\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m agenerate_text_with_retry(\n\u001b[32m    117\u001b[39m     prompt=prompt,\n\u001b[32m    118\u001b[39m     n=n,\n\u001b[32m    119\u001b[39m     temperature=temperature,\n\u001b[32m    120\u001b[39m     stop=stop,\n\u001b[32m    121\u001b[39m     callbacks=callbacks,\n\u001b[32m    122\u001b[39m )\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# check there are no max_token issues\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_finished(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:189\u001b[39m, in \u001b[36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    188\u001b[39m async_wrapped.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tenacity\\_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tenacity\\__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\ragas\\llms\\base.py:294\u001b[39m, in \u001b[36mLangchainLLMWrapper.agenerate_text\u001b[39m\u001b[34m(self, prompt, n, temperature, stop, callbacks)\u001b[39m\n\u001b[32m    288\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.langchain_llm.agenerate_prompt(\n\u001b[32m    289\u001b[39m         prompts=[prompt],\n\u001b[32m    290\u001b[39m         stop=stop,\n\u001b[32m    291\u001b[39m         callbacks=callbacks,\n\u001b[32m    292\u001b[39m     )\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.langchain_llm.agenerate_prompt(\n\u001b[32m    295\u001b[39m         prompts=[prompt] * n,\n\u001b[32m    296\u001b[39m         stop=stop,\n\u001b[32m    297\u001b[39m         callbacks=callbacks,\n\u001b[32m    298\u001b[39m     )\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# make LLMResult.generation appear as if it was n_completions\u001b[39;00m\n\u001b[32m    300\u001b[39m     \u001b[38;5;66;03m# note that LLMResult.runs is still a list that represents each run\u001b[39;00m\n\u001b[32m    301\u001b[39m     generations = [[g[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m result.generations]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1036\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1027\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1033\u001b[39m     **kwargs: Any,\n\u001b[32m   1034\u001b[39m ) -> LLMResult:\n\u001b[32m   1035\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m   1037\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m   1038\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    943\u001b[39m run_managers = \u001b[38;5;28;01mawait\u001b[39;00m callback_manager.on_chat_model_start(\n\u001b[32m    944\u001b[39m     \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m    945\u001b[39m     messages_to_trace,\n\u001b[32m   (...)\u001b[39m\u001b[32m    950\u001b[39m     run_id=run_id,\n\u001b[32m    951\u001b[39m )\n\u001b[32m    953\u001b[39m input_messages = [\n\u001b[32m    954\u001b[39m     _normalize_messages(message_list) \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[32m    955\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    957\u001b[39m     *[\n\u001b[32m    958\u001b[39m         \u001b[38;5;28mself\u001b[39m._agenerate_with_cache(\n\u001b[32m    959\u001b[39m             m,\n\u001b[32m    960\u001b[39m             stop=stop,\n\u001b[32m    961\u001b[39m             run_manager=run_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    962\u001b[39m             **kwargs,\n\u001b[32m    963\u001b[39m         )\n\u001b[32m    964\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages)\n\u001b[32m    965\u001b[39m     ],\n\u001b[32m    966\u001b[39m     return_exceptions=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    967\u001b[39m )\n\u001b[32m    968\u001b[39m exceptions = []\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1164\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1162\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1165\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1166\u001b[39m     )\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:328\u001b[39m, in \u001b[36mChatOllama._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_agenerate\u001b[39m(\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    306\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     **kwargs: Any,\n\u001b[32m    310\u001b[39m ) -> ChatResult:\n\u001b[32m    311\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    312\u001b[39m \n\u001b[32m    313\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     final_chunk = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._achat_stream_with_aggregation(\n\u001b[32m    329\u001b[39m         messages,\n\u001b[32m    330\u001b[39m         stop=stop,\n\u001b[32m    331\u001b[39m         run_manager=run_manager,\n\u001b[32m    332\u001b[39m         verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    333\u001b[39m         **kwargs,\n\u001b[32m    334\u001b[39m     )\n\u001b[32m    335\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    336\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    337\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    338\u001b[39m     )\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:249\u001b[39m, in \u001b[36mChatOllama._achat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_achat_stream_with_aggregation\u001b[39m(\n\u001b[32m    241\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    242\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    246\u001b[39m     **kwargs: Any,\n\u001b[32m    247\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    248\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._acreate_chat_stream(messages, stop, **kwargs):\n\u001b[32m    250\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[32m    251\u001b[39m             chunk = _chat_stream_response_to_chat_generation_chunk(stream_resp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:208\u001b[39m, in \u001b[36mChatOllama._acreate_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_acreate_chat_stream\u001b[39m(\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    200\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    201\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    202\u001b[39m     **kwargs: Any,\n\u001b[32m    203\u001b[39m ) -> AsyncIterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    204\u001b[39m     payload = {\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    207\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._acreate_stream(\n\u001b[32m    209\u001b[39m         payload=payload, stop=stop, api_url=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/chat\u001b[39m\u001b[33m\"\u001b[39m, **kwargs\n\u001b[32m    210\u001b[39m     ):\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m stream_resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:316\u001b[39m, in \u001b[36m_OllamaCommon._acreate_stream\u001b[39m\u001b[34m(self, api_url, payload, stop, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m     request_payload = {\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    311\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m, []),\n\u001b[32m    312\u001b[39m         **params,\n\u001b[32m    313\u001b[39m     }\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aiohttp.ClientSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session.post(\n\u001b[32m    317\u001b[39m         url=api_url,\n\u001b[32m    318\u001b[39m         headers={\n\u001b[32m    319\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m             **(\u001b[38;5;28mself\u001b[39m.headers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.headers, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    321\u001b[39m         },\n\u001b[32m    322\u001b[39m         auth=\u001b[38;5;28mself\u001b[39m.auth,  \u001b[38;5;66;03m# type: ignore[arg-type,unused-ignore]\u001b[39;00m\n\u001b[32m    323\u001b[39m         json=request_payload,\n\u001b[32m    324\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout,  \u001b[38;5;66;03m# type: ignore[arg-type,unused-ignore]\u001b[39;00m\n\u001b[32m    325\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m response.status != \u001b[32m200\u001b[39m:\n\u001b[32m    327\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m response.status == \u001b[32m404\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\aiohttp\\client.py:1488\u001b[39m, in \u001b[36m_BaseRequestContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _RetType:\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m     \u001b[38;5;28mself\u001b[39m._resp: _RetType = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._coro\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._resp.\u001b[34m__aenter__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\aiohttp\\client.py:770\u001b[39m, in \u001b[36mClientSession._request\u001b[39m\u001b[34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size, middlewares)\u001b[39m\n\u001b[32m    767\u001b[39m     handler = _connect_and_send_request\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m handler(req)\n\u001b[32m    771\u001b[39m \u001b[38;5;66;03m# Client connector errors should not be retried\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    773\u001b[39m     ConnectionTimeoutError,\n\u001b[32m    774\u001b[39m     ClientConnectorError,\n\u001b[32m    775\u001b[39m     ClientConnectorCertificateError,\n\u001b[32m    776\u001b[39m     ClientConnectorSSLError,\n\u001b[32m    777\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\aiohttp\\client.py:748\u001b[39m, in \u001b[36mClientSession._request.<locals>._connect_and_send_request\u001b[39m\u001b[34m(req)\u001b[39m\n\u001b[32m    746\u001b[39m resp = \u001b[38;5;28;01mawait\u001b[39;00m req.send(conn)\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m resp.start(conn)\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    750\u001b[39m     resp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\aiohttp\\client_reqrep.py:532\u001b[39m, in \u001b[36mClientResponse.start\u001b[39m\u001b[34m(self, connection)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    531\u001b[39m     protocol = \u001b[38;5;28mself\u001b[39m._protocol\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     message, payload = \u001b[38;5;28;01mawait\u001b[39;00m protocol.read()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m http.HttpProcessingError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[32m    535\u001b[39m         \u001b[38;5;28mself\u001b[39m.request_info,\n\u001b[32m    536\u001b[39m         \u001b[38;5;28mself\u001b[39m.history,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m         headers=exc.headers,\n\u001b[32m    540\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\aiohttp\\streams.py:672\u001b[39m, in \u001b[36mDataQueue.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;28mself\u001b[39m._waiter = \u001b[38;5;28mself\u001b[39m._loop.create_future()\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._waiter\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio.CancelledError, asyncio.TimeoutError):\n\u001b[32m    674\u001b[39m     \u001b[38;5;28mself\u001b[39m._waiter = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Evaluate Sparse RAG\n",
    "print(\"\\n=== Evaluating Sparse RAG (NoiseSensitivity) ===\")\n",
    "sparse_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_sparse, sparse_texts), (query_response, response) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_sparse, \n",
    "    sparse_pairs\n",
    "):\n",
    "    # Sanity check\n",
    "    assert query_gt == query_sparse == query_response, f\"Query mismatch: {query_gt} vs {query_sparse} vs {query_response}\"\n",
    "\n",
    "    sample = SingleTurnSample(\n",
    "    user_input=query_gt,\n",
    "    response=response,\n",
    "    reference=gt_answer,\n",
    "    retrieved_contexts=sparse_texts\n",
    "    )\n",
    "\n",
    "    scorer = NoiseSensitivity(llm=evaluator_llm)\n",
    "    score = await scorer.single_turn_ascore(sample)\n",
    "    \n",
    "    print(f\"Sparse - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    sparse_scores.append((query_gt, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
