{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101027d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nerea\\anaconda3\\envs\\thesis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from typing import List, Dict, Tuple\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    ContextRecall,\n",
    "    ContextPrecision,\n",
    "    NoiseSensitivity\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-ea25363437e1476fadd3e65759d42903\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://chat.campusai.compute.dtu.dk/api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d631825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos cargados correctamente\n",
      "  - Total de preguntas: 24\n"
     ]
    }
   ],
   "source": [
    "# Cargar ground truth\n",
    "with open(\"gt.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gt_data = json.load(f)\n",
    "\n",
    "# Cargar retrieval results dense\n",
    "with open(\"extra/retrieval_results_dense.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rag_data_dense = json.load(f)\n",
    "\n",
    "# Cargar retrieval results sparse\n",
    "with open(\"extra/retrieval_results_sparse.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    bm25_data = json.load(f)\n",
    "\n",
    "# Cargar chat logs\n",
    "with open(\"k_testing/k3/chat_logs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chat_data = json.load(f)\n",
    "\n",
    "print(f\"✓ Datos cargados correctamente\")\n",
    "print(f\"  - Total de preguntas: {len(gt_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9f61c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PREGUNTAS DISPONIBLES ===\n",
      "\n",
      "Índice | Pregunta\n",
      "--------------------------------------------------------------------------------\n",
      "     0 | Which solution is suitable for measuring room acoustics and speech ...\n",
      "     1 | What product should be used for façade sound insulation testing on ...\n",
      "     2 | Which sound source is recommended for calibrated speech intelligibi...\n",
      "     3 | What sound source should be used for ISO 3382-compliant room acoust...\n",
      "     4 | Which product supports compliance with ISO 9612 for workplace noise...\n",
      "     5 | Which product is suitable for investigating environmental noise com...\n",
      "     6 | Which product is designed for measuring exhaust noise in vehicles?\n",
      "     7 | Which product helps verify safe noise emissions from toys and machi...\n",
      "     8 | Which HBK 2255 variant is best suited for long-term environmental n...\n",
      "     9 | Which HBK 2255 variant should be used for evaluating workplace nois...\n",
      "    10 | What HBK 2255 variant is recommended for sound insulation testing i...\n",
      "    11 | Which software module allows isolating specific noise events like b...\n",
      "    12 | Which loudspeaker should be used for measuring airborne sound insul...\n",
      "    13 | What amplifier is recommended for driving the OmniPower sound sourc...\n",
      "    14 | Which amplifier version should be selected if remote control via mo...\n",
      "    15 | What sound source is suitable for ISO 3382 compliant reverberation ...\n",
      "    16 | Which B&K 2245 variant is best suited for sound power measurements ...\n",
      "    17 | What software is required on the B&K 2245 to comply with ISO 3744 f...\n",
      "    18 | Which B&K 2245 variant is suitable for environmental noise surveys ...\n",
      "    19 | What variant should be used for roadside exhaust noise enforcement?\n",
      "    20 | Which sound level meter is best suited for a technician doing quick...\n",
      "    21 | What product variant of HBK 2255 should a small business owner choo...\n",
      "    22 | Which HBK 2255 variant includes both environmental noise monitoring...\n",
      "    23 | What sound level meter is recommended for community noise monitorin...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Mostrar todas las preguntas con sus índices\n",
    "print(\"\\n=== PREGUNTAS DISPONIBLES ===\")\n",
    "print(\"\\nÍndice | Pregunta\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for idx, item in enumerate(gt_data):\n",
    "    question = item[\"question\"].strip()\n",
    "    # Truncar pregunta si es muy larga\n",
    "    display_q = question if len(question) <= 70 else question[:67] + \"...\"\n",
    "    print(f\"{idx:6} | {display_q}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f2bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Seleccionadas 24 preguntas para re-evaluación:\n",
      "  Índices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "\n",
      "Preguntas seleccionadas:\n",
      "--------------------------------------------------------------------------------\n",
      "     0 | Which solution is suitable for measuring room acoustics and speech ...\n",
      "     1 | What product should be used for façade sound insulation testing on ...\n",
      "     2 | Which sound source is recommended for calibrated speech intelligibi...\n",
      "     3 | What sound source should be used for ISO 3382-compliant room acoust...\n",
      "     4 | Which product supports compliance with ISO 9612 for workplace noise...\n",
      "     5 | Which product is suitable for investigating environmental noise com...\n",
      "     6 | Which product is designed for measuring exhaust noise in vehicles?\n",
      "     7 | Which product helps verify safe noise emissions from toys and machi...\n",
      "     8 | Which HBK 2255 variant is best suited for long-term environmental n...\n",
      "     9 | Which HBK 2255 variant should be used for evaluating workplace nois...\n",
      "    10 | What HBK 2255 variant is recommended for sound insulation testing i...\n",
      "    11 | Which software module allows isolating specific noise events like b...\n",
      "    12 | Which loudspeaker should be used for measuring airborne sound insul...\n",
      "    13 | What amplifier is recommended for driving the OmniPower sound sourc...\n",
      "    14 | Which amplifier version should be selected if remote control via mo...\n",
      "    15 | What sound source is suitable for ISO 3382 compliant reverberation ...\n",
      "    16 | Which B&K 2245 variant is best suited for sound power measurements ...\n",
      "    17 | What software is required on the B&K 2245 to comply with ISO 3744 f...\n",
      "    18 | Which B&K 2245 variant is suitable for environmental noise surveys ...\n",
      "    19 | What variant should be used for roadside exhaust noise enforcement?\n",
      "    20 | Which sound level meter is best suited for a technician doing quick...\n",
      "    21 | What product variant of HBK 2255 should a small business owner choo...\n",
      "    22 | Which HBK 2255 variant includes both environmental noise monitoring...\n",
      "    23 | What sound level meter is recommended for community noise monitorin...\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# MODIFICA ESTA LÍNEA CON TUS ÍNDICES\n",
    "# ========================================\n",
    "\n",
    "# SELECTED_INDICES = [22]  # <- Cambia estos números\n",
    "SELECTED_INDICES = list(range(0, 24)) \n",
    "# Ejemplos:\n",
    "# SELECTED_INDICES = [5, 10, 15, 20]  # Preguntas específicas\n",
    "# SELECTED_INDICES = list(range(0, 10))  # Primeras 10 preguntas\n",
    "# SELECTED_INDICES = list(range(20, 30))  # Preguntas 20-29\n",
    "\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n✓ Seleccionadas {len(SELECTED_INDICES)} preguntas para re-evaluación:\")\n",
    "print(f\"  Índices: {SELECTED_INDICES}\\n\")\n",
    "\n",
    "print(\"Preguntas seleccionadas:\")\n",
    "print(\"-\" * 80)\n",
    "for idx in SELECTED_INDICES:\n",
    "    if idx < len(gt_data):\n",
    "        question = gt_data[idx][\"question\"].strip()\n",
    "        display_q = question if len(question) <= 70 else question[:67] + \"...\"\n",
    "        print(f\"{idx:6} | {display_q}\")\n",
    "    else:\n",
    "        print(f\"{idx:6} | ERROR: Índice fuera de rango\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f17218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datos filtrados:\n",
      "  - Ground truth pairs: 24\n",
      "  - Dense retrieval pairs: 24\n",
      "  - Sparse retrieval pairs: 24\n",
      "  - Dense response pairs: 24\n",
      "  - Sparse response pairs: 24\n"
     ]
    }
   ],
   "source": [
    "# Filtrar ground truth data\n",
    "query_texts_pairs = [\n",
    "    (\n",
    "        item[\"question\"].strip(),\n",
    "        item[\"reference\"].strip(),\n",
    "        [seg.strip() for seg in item.get(\"context\", [])]\n",
    "    )\n",
    "    for i, item in enumerate(gt_data)\n",
    "    if i in SELECTED_INDICES\n",
    "]\n",
    "\n",
    "# Filtrar dense retrieval results\n",
    "all_queries_dense = list(rag_data_dense.keys())\n",
    "query_retrieved_pairs_dense = [\n",
    "    (\n",
    "        query,\n",
    "        [item[\"text\"].strip() for item in rag_data_dense[query]]\n",
    "    )\n",
    "    for i, query in enumerate(all_queries_dense)\n",
    "    if i in SELECTED_INDICES\n",
    "]\n",
    "\n",
    "# Filtrar sparse retrieval results\n",
    "query_retrieved_pairs_sparse = [\n",
    "    (\n",
    "        item[\"query\"],\n",
    "        [res[\"window\"].strip() for res in item[\"results\"]]\n",
    "    )\n",
    "    for i, item in enumerate(bm25_data)\n",
    "    if i in SELECTED_INDICES\n",
    "]\n",
    "\n",
    "# Filtrar chat logs\n",
    "dense_pairs = []\n",
    "sparse_pairs = []\n",
    "\n",
    "dense_idx = 0\n",
    "sparse_idx = 0\n",
    "\n",
    "for item in chat_data:\n",
    "    query = item.get(\"query\", \"\").strip()\n",
    "    mode = item.get(\"mode\", \"\").strip().lower()\n",
    "    response = item.get(\"response\", \"\").strip()\n",
    "    \n",
    "    if mode == \"dense rag\":\n",
    "        if dense_idx in SELECTED_INDICES:\n",
    "            dense_pairs.append((query, response))\n",
    "        dense_idx += 1\n",
    "    elif mode == \"sparse rag\":\n",
    "        if sparse_idx in SELECTED_INDICES:\n",
    "            sparse_pairs.append((query, response))\n",
    "        sparse_idx += 1\n",
    "\n",
    "print(f\"✓ Datos filtrados:\")\n",
    "print(f\"  - Ground truth pairs: {len(query_texts_pairs)}\")\n",
    "print(f\"  - Dense retrieval pairs: {len(query_retrieved_pairs_dense)}\")\n",
    "print(f\"  - Sparse retrieval pairs: {len(query_retrieved_pairs_sparse)}\")\n",
    "print(f\"  - Dense response pairs: {len(dense_pairs)}\")\n",
    "print(f\"  - Sparse response pairs: {len(sparse_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba0d8461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LLM y métricas inicializadas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_18636\\2724116588.py:8: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  evaluator_llm = LangchainLLMWrapper(llm)\n"
     ]
    }
   ],
   "source": [
    "# Inicializar LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"DeepSeek-R1\",\n",
    "    temperature=0,\n",
    "    max_retries=3,\n",
    "    request_timeout=300\n",
    ")\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "# Inicializar métricas\n",
    "metrics = {\n",
    "    'faithfulness': Faithfulness(llm=evaluator_llm),\n",
    "    'context_precision': ContextPrecision(llm=evaluator_llm),\n",
    "    'context_recall': ContextRecall(llm=evaluator_llm),\n",
    "    'noise_sensitivity': NoiseSensitivity(llm=evaluator_llm)\n",
    "}\n",
    "\n",
    "print(\"✓ LLM y métricas inicializadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67193ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_metrics(mode, query_texts_pairs, query_retrieved_pairs, response_pairs):\n",
    "    \"\"\"\n",
    "    Evalúa todas las métricas para las preguntas seleccionadas\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"=== Evaluando {mode} RAG - Preguntas Seleccionadas ===\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    all_scores = {metric_name: [] for metric_name in metrics.keys()}\n",
    "    metric_arrays = {metric_name: [] for metric_name in metrics.keys()}\n",
    "    \n",
    "    for idx, ((query_gt, gt_answer, gt_texts), (query_ret, ret_texts), (query_resp, response)) in enumerate(zip(\n",
    "        query_texts_pairs, \n",
    "        query_retrieved_pairs, \n",
    "        response_pairs\n",
    "    ), 1):\n",
    "        # Verificar consistencia\n",
    "        assert query_gt == query_ret == query_resp, f\"Query mismatch: {query_gt} vs {query_ret} vs {query_resp}\"\n",
    "        \n",
    "        print(f\"\\n[{mode} RAG - Pregunta {idx}/{len(query_texts_pairs)}]\")\n",
    "        print(f\"Query: {query_gt[:80]}...\")\n",
    "        \n",
    "        # Crear sample\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=query_gt,\n",
    "            response=response,\n",
    "            reference=gt_answer,\n",
    "            retrieved_contexts=ret_texts\n",
    "        )\n",
    "        \n",
    "        # Evaluar cada métrica\n",
    "        for metric_name, scorer in metrics.items():\n",
    "            try:\n",
    "                score = await scorer.single_turn_ascore(sample)\n",
    "                all_scores[metric_name].append((query_gt, score))\n",
    "                metric_arrays[metric_name].append(round(score, 4))\n",
    "                print(f\"  {metric_name.replace('_', ' ').title()}: {score:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {metric_name.replace('_', ' ').title()}: ERROR - {str(e)}\")\n",
    "                all_scores[metric_name].append((query_gt, None))\n",
    "                metric_arrays[metric_name].append(None)\n",
    "    \n",
    "    return all_scores, metric_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be8a84",
   "metadata": {},
   "source": [
    "## 8. Ejecutar Evaluación para Sparse RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4500265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "=== Evaluando Sparse RAG - Preguntas Seleccionadas ===\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Sparse RAG - Pregunta 1/1]\n",
      "Query: Which HBK 2255 variant includes both environmental noise monitoring and a calibr...\n",
      "  Faithfulness: 1.0000\n",
      "  Context Precision: 0.0000\n",
      "  Context Recall: 0.0000\n",
      "  Noise Sensitivity: 0.5000\n"
     ]
    }
   ],
   "source": [
    "sparse_scores, sparse_arrays = await evaluate_metrics(\n",
    "    \"Sparse\",\n",
    "    query_texts_pairs,\n",
    "    query_retrieved_pairs_sparse,\n",
    "    sparse_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ceb78",
   "metadata": {},
   "source": [
    "## 9. Ejecutar Evaluación para Dense RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "=== Evaluando Dense RAG - Preguntas Seleccionadas ===\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Dense RAG - Pregunta 1/24]\n",
      "Query: Which solution is suitable for measuring room acoustics and speech intelligibili...\n"
     ]
    }
   ],
   "source": [
    "dense_scores, dense_arrays = await evaluate_metrics(\n",
    "    \"Dense\",\n",
    "    query_texts_pairs,\n",
    "    query_retrieved_pairs_dense,\n",
    "    dense_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5988bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "=== RESULTADOS DETALLADOS ===\n",
      "======================================================================\n",
      "\n",
      "--- Sparse RAG ---\n",
      "\n",
      "Faithfulness:\n",
      "  Valores: [0.0]\n",
      "  Promedio: 0.0000\n",
      "\n",
      "Context Precision:\n",
      "  Valores: [0.0]\n",
      "  Promedio: 0.0000\n",
      "\n",
      "Context Recall:\n",
      "  Valores: [0.0]\n",
      "  Promedio: 0.0000\n",
      "\n",
      "Noise Sensitivity:\n",
      "  Valores: [0.0]\n",
      "  Promedio: 0.0000\n",
      "\n",
      "--- Dense RAG ---\n",
      "\n",
      "Faithfulness:\n",
      "  Valores: [1.0]\n",
      "  Promedio: 1.0000\n",
      "\n",
      "Context Precision:\n",
      "  Valores: [0.5]\n",
      "  Promedio: 0.5000\n",
      "\n",
      "Context Recall:\n",
      "  Valores: [1.0]\n",
      "  Promedio: 1.0000\n",
      "\n",
      "Noise Sensitivity:\n",
      "  Valores: [0.75]\n",
      "  Promedio: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Mostrar resultados detallados\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"=== RESULTADOS DETALLADOS ===\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metric_names = ['faithfulness', 'context_precision', 'context_recall', 'noise_sensitivity']\n",
    "\n",
    "print(\"\\n--- Sparse RAG ---\")\n",
    "for metric_name in metric_names:\n",
    "    print(f\"\\n{metric_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Valores: {sparse_arrays[metric_name]}\")\n",
    "    valid_scores = [s for s in sparse_arrays[metric_name] if s is not None]\n",
    "    if valid_scores:\n",
    "        avg = sum(valid_scores) / len(valid_scores)\n",
    "        print(f\"  Promedio: {avg:.4f}\")\n",
    "\n",
    "print(\"\\n--- Dense RAG ---\")\n",
    "for metric_name in metric_names:\n",
    "    print(f\"\\n{metric_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Valores: {dense_arrays[metric_name]}\")\n",
    "    valid_scores = [s for s in dense_arrays[metric_name] if s is not None]\n",
    "    if valid_scores:\n",
    "        avg = sum(valid_scores) / len(valid_scores)\n",
    "        print(f\"  Promedio: {avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
