{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import NonLLMContextPrecisionWithReference\n",
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
    "from ragas.metrics import NoiseSensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b571152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "evaluator_llm = LangchainLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = r\"gt.json\"\n",
    "\n",
    "# Load the JSON safely\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Build a list of tuples: (question, reference_answer, [list of context texts])\n",
    "query_texts_pairs = [\n",
    "    (\n",
    "        item[\"question\"].strip(),\n",
    "        item[\"reference\"].strip(),\n",
    "        [seg.strip() for seg in item.get(\"context\", [])]\n",
    "    )\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# Example: show the first query and its data\n",
    "first_query, first_reference, first_contexts = query_texts_pairs[0]\n",
    "print(\"Query:\", first_query)\n",
    "print(\"Reference answer:\", first_reference)\n",
    "print(\"Number of context texts:\", len(first_contexts))\n",
    "print(\"First context snippet:\", first_contexts[0][:200].replace(\"\\n\", \" \"), \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your RAG output JSON\n",
    "path = r\"retrieval_results_dense.json\"\n",
    "\n",
    "# Load the JSON\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    rag_data_dense = json.load(f)\n",
    "\n",
    "# Build a list of tuples: (query, [list of retrieved texts])\n",
    "query_retrieved_pairs_dense = [\n",
    "    (\n",
    "        query,\n",
    "        [item[\"text\"].strip() for item in texts]\n",
    "    )\n",
    "    for query, texts in rag_data_dense.items()\n",
    "]\n",
    "\n",
    "# Example: show the first query and its retrieved texts\n",
    "first_query, first_texts = query_retrieved_pairs_dense[0]\n",
    "print(\"Query:\", first_query)\n",
    "print(\"Number of retrieved texts:\", len(first_texts))\n",
    "print(\"First retrieved text snippet:\", first_texts[0][:200].replace(\"\\n\", \" \"), \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b01d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your BM25 output JSON\n",
    "path = r\"retrieval_results_sparse.json\"\n",
    "\n",
    "# Load the JSON\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    bm25_data = json.load(f)\n",
    "\n",
    "# Build a list of tuples: (query, [list of retrieved texts])\n",
    "query_retrieved_pairs_sparse = [\n",
    "    (\n",
    "        item[\"query\"],\n",
    "        [res[\"window\"].strip() for res in item[\"results\"]]\n",
    "    )\n",
    "    for item in bm25_data\n",
    "]\n",
    "\n",
    "# Example: show the first query and its retrieved texts\n",
    "first_query, first_texts = query_retrieved_pairs_sparse[0]\n",
    "print(\"Query:\", first_query)\n",
    "print(\"Number of retrieved texts:\", len(first_texts))\n",
    "print(\"First retrieved text snippet:\", first_texts[0][:200].replace(\"\\n\", \" \"), \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3266ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chat logs and separate by mode\n",
    "path = r\"chat_logs.json\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dense_pairs = []\n",
    "sparse_pairs = []\n",
    "\n",
    "for item in data:\n",
    "    query = item.get(\"query\", \"\").strip()\n",
    "    mode = item.get(\"mode\", \"\").strip().lower()\n",
    "    response = item.get(\"response\", \"\").strip()\n",
    "    \n",
    "    if mode == \"dense rag\":\n",
    "        dense_pairs.append((query, response))\n",
    "    elif mode == \"sparse rag\":\n",
    "        sparse_pairs.append((query, response))\n",
    "\n",
    "print(\"Dense pairs found:\", len(dense_pairs))\n",
    "print(\"Sparse pairs found:\", len(sparse_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Sparse RAG\n",
    "print(\"\\n=== Evaluating Sparse RAG (NoiseSensitivity) ===\")\n",
    "sparse_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_sparse, sparse_texts), (query_response, response) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_sparse, \n",
    "    sparse_pairs\n",
    "):\n",
    "    # Sanity check\n",
    "    assert query_gt == query_sparse == query_response, f\"Query mismatch: {query_gt} vs {query_sparse} vs {query_response}\"\n",
    "\n",
    "    sample = SingleTurnSample(\n",
    "    user_input=query_gt,\n",
    "    response=response,\n",
    "    reference=gt_answer,\n",
    "    retrieved_contexts=sparse_texts\n",
    "    )\n",
    "\n",
    "    scorer = NoiseSensitivity(llm=evaluator_llm)\n",
    "    score = await scorer.single_turn_ascore(sample)\n",
    "    \n",
    "    print(f\"Sparse - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    sparse_scores.append((query_gt, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Sparse RAG\n",
    "print(\"\\n=== Evaluating Dense RAG (NoiseSensitivity) ===\")\n",
    "dense_scores = []\n",
    "\n",
    "for (query_gt, gt_answer, gt_texts), (query_dense, dense_texts), (query_response, response) in zip(\n",
    "    query_texts_pairs, \n",
    "    query_retrieved_pairs_dense, \n",
    "    dense_pairs\n",
    "):\n",
    "    # Sanity check\n",
    "    assert query_gt == query_dense == query_response, f\"Query mismatch: {query_gt} vs {query_dense} vs {query_response}\"\n",
    "    sample = SingleTurnSample(\n",
    "    user_input=query_gt,\n",
    "    response=response,\n",
    "    reference=gt_answer,\n",
    "    retrieved_contexts=dense_texts\n",
    "    )\n",
    "\n",
    "    scorer = NoiseSensitivity(llm=evaluator_llm)\n",
    "    score = await scorer.single_turn_ascore(sample)\n",
    "    \n",
    "    print(f\"Dense - Query: {query_gt[:60]}... Score: {score}\")\n",
    "    dense_scores.append((query_gt, score))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
